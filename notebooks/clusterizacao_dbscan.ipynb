{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import spark_partition_id, col\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/11/30 19:15:35 WARN Utils: Your hostname, matt resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/11/30 19:15:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/30 19:15:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DBSCANClustering\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"../data/dblp-v10-processado-vetorizado-word2vec.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract',\n",
       " 'title',\n",
       " 'title_word2vec',\n",
       " 'abstract_word2vec',\n",
       " 'features',\n",
       " 'norm_features']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- abstract: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- title: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- title_word2vec: vector (nullable = true)\n",
      " |-- abstract_word2vec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- norm_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de partições para processar os dados em partes menores\n",
    "num_partitions = 10\n",
    "df_partitioned = df.repartition(num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros do DBSCAN\n",
    "eps = 0.5  # Distância máxima para considerar vizinhos\n",
    "min_samples = 10  # Número mínimo de pontos para formar um cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição 0: 82754 vetores\n",
      "Clusters encontrados na partição 0: 60 (inclui ruído)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição 1: 82753 vetores\n",
      "Clusters encontrados na partição 1: 56 (inclui ruído)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição 2: 82755 vetores\n",
      "Clusters encontrados na partição 2: 69 (inclui ruído)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição 3: 82755 vetores\n",
      "Clusters encontrados na partição 3: 59 (inclui ruído)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição 4: 82757 vetores\n",
      "Clusters encontrados na partição 4: 66 (inclui ruído)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição 5: 82754 vetores\n",
      "Clusters encontrados na partição 5: 60 (inclui ruído)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição 6: 82754 vetores\n",
      "Clusters encontrados na partição 6: 62 (inclui ruído)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição 7: 82752 vetores\n",
      "Clusters encontrados na partição 7: 49 (inclui ruído)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição 8: 82748 vetores\n",
      "Clusters encontrados na partição 8: 59 (inclui ruído)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição 9: 82751 vetores\n",
      "Clusters encontrados na partição 9: 60 (inclui ruído)\n"
     ]
    }
   ],
   "source": [
    "# Lista para armazenar os resultados de cada partição\n",
    "results = []\n",
    "\n",
    "# Iterar sobre cada partição\n",
    "for i in range(num_partitions):\n",
    "    # Filtrar apenas os dados da partição atual\n",
    "    partition_df = df_partitioned.filter(spark_partition_id() == i)\n",
    "    \n",
    "    # Extrair os vetores densos da partição como uma lista de arrays numpy\n",
    "    features = partition_df.select(col(\"norm_features\")).rdd.map(lambda row: row[0].toArray()).collect()\n",
    "    features_array = np.array(features)\n",
    "    \n",
    "    # Informar o tamanho dos dados na partição\n",
    "    print(f\"Partição {i}: {features_array.shape[0]} vetores\")\n",
    "    \n",
    "    # Aplicar o DBSCAN na partição\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    cluster_labels = dbscan.fit_predict(features_array)\n",
    "    \n",
    "    # Informar a quantidade de clusters encontrados\n",
    "    print(f\"Clusters encontrados na partição {i}: {len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)} (inclui ruído)\")\n",
    "    \n",
    "    # Criar um DataFrame Spark com os rótulos de cluster\n",
    "    partition_result = spark.createDataFrame(\n",
    "        [(int(cluster_id),) for cluster_id in cluster_labels],\n",
    "        [\"cluster_label\"]\n",
    "    )\n",
    "    \n",
    "    # Adicionar os resultados a uma lista\n",
    "    results.append(partition_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar os resultados de todas as partições\n",
    "result_df = results[0]\n",
    "for partition_result in results[1:]:\n",
    "    result_df = result_df.union(partition_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar os rótulos de cluster ao DataFrame original\n",
    "df_with_clusters = df_partitioned.withColumn(\"partition_id\", spark_partition_id()) \\\n",
    "    .join(result_df.withColumn(\"partition_id\", spark_partition_id()), on=\"partition_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['partition_id',\n",
       " 'abstract',\n",
       " 'title',\n",
       " 'title_word2vec',\n",
       " 'abstract_word2vec',\n",
       " 'features',\n",
       " 'norm_features',\n",
       " 'cluster_label']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_clusters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o DataFrame resultante com os rótulos de cluster\n",
    "# df_with_clusters.write.parquet(\"dbscan_clusters.parquet\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
